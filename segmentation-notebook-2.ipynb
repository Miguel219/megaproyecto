{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se importan las librerías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import albumentations as A\n",
    "\n",
    "from torchgeo.datasets import LoveDA\n",
    "\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"PyTorch utiliza {}\".format(\"GPU\" if torch.cuda.is_available() else \"CPU\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = './segmentation-loveDA/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones Útiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_gpu_cache(verbose=False):\n",
    "    if verbose:\n",
    "        print(\"Initial GPU Usage\")\n",
    "        gpu_usage()                             \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"GPU Usage after emptying the cache\")\n",
    "        gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(LoveDA):\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        files = self.files[index]\n",
    "        # Se lee la imagen según su indice\n",
    "        image = cv2.imread(files[\"image\"])\n",
    "        # Convierte los colores de la imagen de BGR a RGB  \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.split != \"test\":\n",
    "            mask = cv2.imread(files[\"mask\"], cv2.IMREAD_GRAYSCALE)\n",
    "            sample = {\"image\": image, \"mask\": mask}\n",
    "        else:\n",
    "            sample = {\"image\": image}\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            sample = self.transforms(**sample)\n",
    "\n",
    "        sample['image'] = Image.fromarray(sample['image'])\n",
    "        \n",
    "        t = T.Compose([T.ToTensor()])\n",
    "        sample['image'] = t(sample['image'])\n",
    "\n",
    "        if self.split != \"test\":\n",
    "            sample['mask'] = torch.from_numpy(sample['mask']).long()\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_accuracy(output, mask):\n",
    "    with torch.no_grad():\n",
    "        output = torch.argmax(F.softmax(output, dim=1), dim=1)\n",
    "        correct = torch.eq(output, mask).int()\n",
    "        accuracy = float(correct.sum()) / float(correct.numel())\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean intersection over union\n",
    "def mIoU(pred_mask, mask, smooth=1e-10, n_classes=8):\n",
    "    with torch.no_grad():\n",
    "        pred_mask = F.softmax(pred_mask, dim=1)\n",
    "        pred_mask = torch.argmax(pred_mask, dim=1)\n",
    "        pred_mask = pred_mask.contiguous().view(-1)\n",
    "        mask = mask.contiguous().view(-1)\n",
    "\n",
    "        iou_per_class = []\n",
    "        for clas in range(0, n_classes): #loop per pixel class\n",
    "            true_class = pred_mask == clas\n",
    "            true_label = mask == clas\n",
    "\n",
    "            if true_label.long().sum().item() == 0: #no exist label in this loop\n",
    "                iou_per_class.append(np.nan)\n",
    "            else:\n",
    "                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n",
    "                union = torch.logical_or(true_class, true_label).sum().float().item()\n",
    "\n",
    "                iou = (intersect + smooth) / (union +smooth)\n",
    "                iou_per_class.append(iou)\n",
    "        return np.nanmean(iou_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler):\n",
    "    free_gpu_cache()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_iou = []\n",
    "    val_acc = []\n",
    "    train_iou = []\n",
    "    train_acc = []\n",
    "    lrs = []\n",
    "    min_loss = np.inf\n",
    "    not_improve = 0\n",
    "\n",
    "    model.to(device)\n",
    "    fit_time = time.time()\n",
    "    for e in range(epochs):\n",
    "        since = time.time()\n",
    "        running_loss = 0\n",
    "        iou_score = 0\n",
    "        accuracy = 0\n",
    "        #training loop\n",
    "        model.train()\n",
    "        for i, data in enumerate(train_loader):\n",
    "            #training phase\n",
    "            image_tiles = data['image']    \n",
    "            mask_tiles = data['mask']      \n",
    "            image = image_tiles.to(device)\n",
    "            mask = mask_tiles.to(device)\n",
    "            #forward\n",
    "            output = model(image)\n",
    "            loss = criterion(output, mask)\n",
    "            #evaluation metrics\n",
    "            iou_score += mIoU(output, mask)\n",
    "            accuracy += pixel_accuracy(output, mask)\n",
    "            #backward\n",
    "            loss.backward()\n",
    "            optimizer.step() #update weight          \n",
    "            optimizer.zero_grad() #reset gradient\n",
    "            \n",
    "            #step the learning rate\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            scheduler.step() \n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        else:\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            val_accuracy = 0\n",
    "            val_iou_score = 0\n",
    "            #validation loop\n",
    "            with torch.no_grad():\n",
    "                for i, data in enumerate(val_loader):\n",
    "                    #reshape to 9 patches from single image, delete batch size\n",
    "                    image_tiles = data['image']            \n",
    "                    mask_tiles = data['mask']    \n",
    "                    image = image_tiles.to(device)\n",
    "                    mask = mask_tiles.to(device)\n",
    "                    output = model(image)\n",
    "                    #evaluation metrics\n",
    "                    val_iou_score +=  mIoU(output, mask)\n",
    "                    val_accuracy += pixel_accuracy(output, mask)\n",
    "                    #loss\n",
    "                    loss = criterion(output, mask)                                  \n",
    "                    val_loss += loss.item()\n",
    "            \n",
    "            #calculatio mean for each batch\n",
    "            train_losses.append(running_loss/len(train_loader))\n",
    "            val_losses.append(val_loss/len(val_loader))                    \n",
    "\n",
    "            if (val_loss/len(val_loader)) > min_loss:\n",
    "                not_improve += 1\n",
    "                min_loss = (val_loss/len(val_loader))\n",
    "                print(f'Loss Not Decrease for {not_improve} time')\n",
    "                if not_improve == 7:\n",
    "                    print('Loss not decrease for 7 times, Stop Training')\n",
    "                    break\n",
    "            \n",
    "            #iou\n",
    "            val_iou.append(val_iou_score/len(val_loader))\n",
    "            train_iou.append(iou_score/len(train_loader))\n",
    "            train_acc.append(accuracy/len(train_loader))\n",
    "            val_acc.append(val_accuracy/ len(val_loader))\n",
    "            print(\"Epoch:{}/{}..\".format(e+1, epochs),\n",
    "                  \"Train Loss: {:.3f}..\".format(running_loss/len(train_loader)),\n",
    "                  \"Val Loss: {:.3f}..\".format(val_loss/len(val_loader)),\n",
    "                  \"Train mIoU:{:.3f}..\".format(iou_score/len(train_loader)),\n",
    "                  \"Val mIoU: {:.3f}..\".format(val_iou_score/len(val_loader)),\n",
    "                  \"Train Acc:{:.3f}..\".format(accuracy/len(train_loader)),\n",
    "                  \"Val Acc:{:.3f}..\".format(val_accuracy/len(val_loader)),\n",
    "                  \"Time: {:.2f}m\".format((time.time()-since)/60))\n",
    "        \n",
    "    history = {'train_loss' : train_losses, 'val_loss': val_losses,\n",
    "               'train_miou' :train_iou, 'val_miou':val_iou,\n",
    "               'train_acc' :train_acc, 'val_acc':val_acc,\n",
    "               'lrs': lrs}\n",
    "    print('Total time: {:.2f} m' .format((time.time()- fit_time)/60))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image_mask_miou(model, image, mask):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    image=image.to(device)\n",
    "    mask = mask.to(device)\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        image = image.unsqueeze(0)\n",
    "        mask = mask.unsqueeze(0)\n",
    "        \n",
    "        output = model(image)\n",
    "        score = mIoU(output, mask)\n",
    "        masked = torch.argmax(output, dim=1)\n",
    "        masked = masked.cpu().squeeze(0)\n",
    "    return masked, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image_mask_pixel(model, image, mask):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    image=image.to(device)\n",
    "    mask = mask.to(device)\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        image = image.unsqueeze(0)\n",
    "        mask = mask.unsqueeze(0)\n",
    "        \n",
    "        output = model(image)\n",
    "        acc = pixel_accuracy(output, mask)\n",
    "        masked = torch.argmax(output, dim=1)\n",
    "        masked = masked.cpu().squeeze(0)\n",
    "    return masked, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image_mask(model, image):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    image=image.to(device)\n",
    "    with torch.no_grad():\n",
    "        image = image.unsqueeze(0)\n",
    "        \n",
    "    output = model(image)\n",
    "    masked = torch.argmax(output, dim=1)\n",
    "    masked = masked.cpu().squeeze(0)\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def miou_score(model, test_set):\n",
    "    score_iou = []\n",
    "    for i in range(len(test_set)):\n",
    "        img, mask = test_set[i]\n",
    "        pred_mask, score = predict_image_mask_miou(model, img, mask)\n",
    "        score_iou.append(score)\n",
    "    return score_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_acc(model, test_set):\n",
    "    accuracy = []\n",
    "    for i in range(len(test_set)):\n",
    "        img, mask = test_set[i]\n",
    "        pred_mask, acc = predict_image_mask_pixel(model, img, mask)\n",
    "        accuracy.append(acc)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_colortable(colors, title, sort_colors=True, emptycols=0):\n",
    "\n",
    "    cell_width = 212\n",
    "    cell_height = 22\n",
    "    swatch_width = 48\n",
    "    margin = 12\n",
    "    topmargin = 40\n",
    "\n",
    "    # Sort colors by hue, saturation, value and name.\n",
    "    if sort_colors is True:\n",
    "        by_hsv = sorted((tuple(mcolors.rgb_to_hsv(mcolors.to_rgb(color))),\n",
    "                         name)\n",
    "                        for name, color in colors.items())\n",
    "        names = [name for hsv, name in by_hsv]\n",
    "    else:\n",
    "        names = list(colors)\n",
    "\n",
    "    n = len(names)\n",
    "    ncols = 4 - emptycols\n",
    "    nrows = n // ncols + int(n % ncols > 0)\n",
    "\n",
    "    width = cell_width * 4 + 2 * margin\n",
    "    height = cell_height * nrows + margin + topmargin\n",
    "    dpi = 72\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(width / dpi, height / dpi), dpi=dpi)\n",
    "    fig.subplots_adjust(margin/width, margin/height,\n",
    "                        (width-margin)/width, (height-topmargin)/height)\n",
    "    ax.set_xlim(0, cell_width * 4)\n",
    "    ax.set_ylim(cell_height * (nrows-0.5), -cell_height/2.)\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(title, fontsize=24, loc=\"left\", pad=10)\n",
    "\n",
    "    for i, name in enumerate(names):\n",
    "        row = i % nrows\n",
    "        col = i // nrows\n",
    "        y = row * cell_height\n",
    "\n",
    "        swatch_start_x = cell_width * col\n",
    "        text_pos_x = cell_width * col + swatch_width + 7\n",
    "\n",
    "        ax.text(text_pos_x, y, name, fontsize=14,\n",
    "                horizontalalignment='left',\n",
    "                verticalalignment='center')\n",
    "\n",
    "        ax.add_patch(\n",
    "            Rectangle(xy=(swatch_start_x, y-9), width=swatch_width,\n",
    "                      height=18, facecolor=colors[name], edgecolor='0.7')\n",
    "        )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear los datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = A.Compose([A.HorizontalFlip(), A.VerticalFlip(), A.GridDistortion(p=0.2), \n",
    "                             A.RandomBrightnessContrast((0,0.5),(0,0.5)), A.GaussNoise()])\n",
    "transform_val = A.Compose([A.HorizontalFlip(), A.GridDistortion(p=0.2)])\n",
    "\n",
    "\n",
    "#datasets\n",
    "train_set = CustomDataset(root=ROOT_PATH, split=\"train\", transforms=transform_train)\n",
    "val_set = CustomDataset(root=ROOT_PATH, split=\"val\", transforms=transform_val)\n",
    "test_set = CustomDataset(root=ROOT_PATH, split=\"test\")\n",
    "\n",
    "#dataloader\n",
    "batch_size= 1\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = len(train_set) + len(val_set) + len(test_set)\n",
    "print('Train Size:', len(train_set), '({}%)'.format(round((len(train_set)/total_len)*100, 2)))\n",
    "print('Val Size:', len(val_set), '({}%)'.format(round((len(val_set)/total_len)*100, 2)))\n",
    "print('Test Size:', len(test_set), '({}%)'.format(round((len(test_set)/total_len)*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_set[5]\n",
    "\n",
    "t = T.Compose([T.ToPILImage()])\n",
    "data['image'] = t(data['image'])\n",
    "\n",
    "print('Tamaño de imagen:', np.asarray(data['image']).shape)\n",
    "print('Tamaño de máscara:', np.asarray(data['mask']).shape)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(20,10))\n",
    "ax1.imshow(data['image'])\n",
    "ax1.set_title('Imagen')\n",
    "\n",
    "ax2.imshow(data['mask'])\n",
    "ax2.set_title('Máscara')\n",
    "ax2.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet('mobilenet_v2', encoder_weights='imagenet', classes=n_classes, activation=None, \n",
    "    encoder_depth=5, decoder_channels=[256, 128, 64, 32, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lr = 1e-3\n",
    "epoch = 15\n",
    "weight_decay = 1e-4\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=weight_decay)\n",
    "sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epoch,\n",
    "                                            steps_per_epoch=len(train_loader))\n",
    "\n",
    "history = fit(epoch, model, train_loader, val_loader, criterion, optimizer, sched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './models/segmentation-unet-2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['val_loss'], label='val', marker='o')\n",
    "plt.plot( history['train_loss'], label='train', marker='o')\n",
    "plt.title('Loss per epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(), plt.grid()\n",
    "plt.show()\n",
    "    \n",
    "plt.plot(history['train_miou'], label='train_mIoU', marker='*')\n",
    "plt.plot(history['val_miou'], label='val_mIoU',  marker='*')\n",
    "plt.title('Score per epoch')\n",
    "plt.ylabel('mean IoU')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(), plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history['train_acc'], label='train_accuracy', marker='*')\n",
    "plt.plot(history['val_acc'], label='val_accuracy',  marker='*')\n",
    "plt.title('Accuracy per epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(), plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./models/segmentation-unet-2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = test_set[5]\n",
    "pred_mask, score = predict_image_mask_miou(model, image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(20,10))\n",
    "ax1.imshow(image)\n",
    "ax1.set_title('Imagen')\n",
    "\n",
    "ax2.imshow(mask)\n",
    "ax2.set_title('Máscara')\n",
    "ax2.set_axis_off()\n",
    "\n",
    "ax3.imshow(pred_mask)\n",
    "ax3.set_title('Predicción de la máscara'.format(score))\n",
    "ax3.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mob_miou = miou_score(model, test_set)\n",
    "print('Test Set mIoU', np.mean(mob_miou))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mob_acc = pixel_acc(model, test_set)\n",
    "print('Test Set Pixel Accuracy', np.mean(mob_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar imágen del proyecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se lee la imagen según su indice\n",
    "image = cv2.imread('./data/02/ORTO.tif')\n",
    "# Convierte los colores de la imagen de BGR a RGB  \n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "transform = A.Resize(768, 1152, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "aug = transform(image=image)\n",
    "image = Image.fromarray(aug['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mask = predict_image_mask(model, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(20,10))\n",
    "ax1.imshow(image)\n",
    "ax1.set_title('Imagen')\n",
    "\n",
    "ax2.imshow(pred_mask)\n",
    "ax2.set_title('Predicción de la máscara'.format(score))\n",
    "ax2.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./segmentation/class_dict_seg.csv\") \n",
    "data = data.set_index('name')\n",
    "data = data.to_dict()\n",
    "colors = dict()\n",
    "for key in data[' r'].keys():\n",
    "    colors[key] = (data[' r'][key]/255, data[' g'][key]/255, data[' b'][key]/255)\n",
    "plot_colortable(colors, \"Colores de la segmentación:\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('geo_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9c0c391c6ceede039726100339536f42595e366b391c455e167086b0818566c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
